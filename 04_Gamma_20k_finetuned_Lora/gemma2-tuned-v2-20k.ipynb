{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10177348,"sourceType":"datasetVersion","datasetId":6286164},{"sourceId":10215900,"sourceType":"datasetVersion","datasetId":6314574}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install peft\n!pip install trl\n!pip install torch\n!pip install bitsandbytes\n!pip install accelerate\n#!pip install wandb\n!pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:34:19.306472Z","iopub.execute_input":"2024-12-17T07:34:19.306819Z","iopub.status.idle":"2024-12-17T07:35:21.366204Z","shell.execute_reply.started":"2024-12-17T07:34:19.306771Z","shell.execute_reply":"2024-12-17T07:35:21.365262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\n#import wandb\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig, \n    TrainingArguments, \n    logging\n)\nfrom peft import LoraConfig, get_peft_model\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom trl import SFTTrainer, setup_chat_format, SFTConfig\nimport bitsandbytes as bnb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_token\")\nlogin(token=hf_token)\n\nbase_model = \"google/gemma-2b-it\"\nnew_model = \"gemma2-2b-it-test-tuned_v2\"\n\nif torch.cuda.get_device_capability()[0] >= 8:\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\n    !pip install -qqq flash-attn  \nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:21.368511Z","iopub.execute_input":"2024-12-17T07:35:21.369165Z","iopub.status.idle":"2024-12-17T07:35:41.45942Z","shell.execute_reply.started":"2024-12-17T07:35:21.369122Z","shell.execute_reply":"2024-12-17T07:35:41.45874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED']=\"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:41.460267Z","iopub.execute_input":"2024-12-17T07:35:41.460525Z","iopub.status.idle":"2024-12-17T07:35:41.464608Z","shell.execute_reply.started":"2024-12-17T07:35:41.460501Z","shell.execute_reply":"2024-12-17T07:35:41.463625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:35:41.467169Z","iopub.execute_input":"2024-12-17T07:35:41.46759Z","iopub.status.idle":"2024-12-17T07:37:50.980238Z","shell.execute_reply.started":"2024-12-17T07:35:41.467548Z","shell.execute_reply":"2024-12-17T07:37:50.979249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=8,\n    task_type=\"CAUSAL_LM\",\n    target_modules= [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\"]\n)\n\ntokenizer.chat_template = None # Reset the chat template to prevent duplication error\n\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:50.981418Z","iopub.execute_input":"2024-12-17T07:37:50.981778Z","iopub.status.idle":"2024-12-17T07:37:53.939302Z","shell.execute_reply.started":"2024-12-17T07:37:50.981739Z","shell.execute_reply":"2024-12-17T07:37:53.938362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndataset = load_dataset(\"csv\",data_files= \"/kaggle/input/20k-qna-training-data/training_data_20k_qnq.csv\")\ndataset = dataset.shuffle(seed=42)\n\ndef clean_text(text):\n    \"\"\"Clean the input text by removing extra spaces and trimming.\"\"\"\n    return re.sub(r'\\s+', ' ', text).strip()\n\ndef custom_chat_template(batch):\n    \"\"\"Creates chat-style templates for each entry in the batch.\"\"\"\n    \n    # Clean the text fields in each batch\n    question = clean_text(batch['question'])\n    answer = clean_text(batch['answer'])\n    context = clean_text(batch['context'])\n    reasoning = clean_text(batch['reasoning'])\n\n    # Structure the data in a conversation format\n    row_json = [\n        {\"role\": \"user\", \"content\": question},\n        {\"role\": \"system\", \"content\": context},\n        {\"role\": \"assistant\", \"content\": f\"{answer} + ' ' + {reasoning}\"}\n    ]\n    \n    # Debug: Check the row_json structure\n    #print(\"Row JSON: \", row_json)\n\n    # Apply the tokenizer's chat template (assuming it handles JSON-like structures)\n    try:\n        batch['prompt'] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    except Exception as e:\n        print(\"Error in applying chat template:\", e)\n    \n    # Return the modified batch with the new 'prompt' field\n    return batch\n\nprint('~~~~~>')\nprint('Applying custom chat template')\nprint('~~~~~>')\n\n# Apply the custom chat template to each batch in the dataset\ndataset = dataset.map(custom_chat_template)\n\nprint('~~~~~>')\nprint('Success')\nprint('~~~~~>')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:53.940526Z","iopub.execute_input":"2024-12-17T07:37:53.940966Z","iopub.status.idle":"2024-12-17T07:37:59.383687Z","shell.execute_reply.started":"2024-12-17T07:37:53.940926Z","shell.execute_reply":"2024-12-17T07:37:59.382763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dataset['train'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:59.38483Z","iopub.execute_input":"2024-12-17T07:37:59.385105Z","iopub.status.idle":"2024-12-17T07:37:59.389719Z","shell.execute_reply.started":"2024-12-17T07:37:59.385078Z","shell.execute_reply":"2024-12-17T07:37:59.388898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    train_dataset = dataset[\"train\"],\n    args = SFTConfig(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 1,\n        warmup_steps = 2,\n        learning_rate = 2e-4,\n        fp16 = True,\n        logging_steps = 100,\n        do_eval=False,\n        output_dir = new_model,\n        optim = \"paged_adamw_8bit\",\n        dataset_text_field = 'prompt',\n        save_steps = None,\n        save_total_limit = 1,\n        save_strategy = 'no',\n        num_train_epochs=1,\n        \n    ),\n    peft_config = peft_config,\n    tokenizer = tokenizer\n\n)\nmodel.config.use_cache = False\n!rm -rf ~/.cache/huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T07:37:59.391082Z","iopub.execute_input":"2024-12-17T07:37:59.391547Z","iopub.status.idle":"2024-12-17T07:38:09.061612Z","shell.execute_reply.started":"2024-12-17T07:37:59.391479Z","shell.execute_reply":"2024-12-17T07:38:09.060408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('~~~->')\nprint('training started')\nprint('~~~->')\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clear all files and directories in /kaggle/working\n!rm -rf /kaggle/working/*\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_token\")\nlogin(token=hf_token)\n\ntrainer.model.save_pretrained(new_model)\ntokenizer.save_pretrained(new_model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel\n\ntokenizer = AutoTokenizer.from_pretrained(new_model, trust_remote_code=True)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\nmodel.resize_token_embeddings(len(tokenizer))\n\nmodel = PeftModel.from_pretrained(model, new_model)\nmodel = model.merge_and_unload()\n\n# Reload tokenizer to save it\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"message = [\n    {\"role\": \"user\", \"content\": \"What is the GSTIN of the company billing to Manjrekar & Sons?\"},\n    {\"role\": \"system\", \"content\": '{\"Key_value_data\": [{\"Invoice No.\": \"RTR354\", \"Invoice Date\": \"2-Dec-20\", \"Invoice From-Company Name\": \"National Enterprises\", \"Invoice From-Company GSTIN\": \"29AACCT3705E000\", \"Invoice From-Company Email\": \"\", \"Invoice From-Company Phone No.\": \"\", \"Invoice From-Company Address\": \"HSR Layout\\nBangalore\", \"Invoice To-Company Name\": \"Manjrekar & Sons\", \"Invoice To-Company GSTIN\": \"27BJPJK0301P1ZT\", \"Invoice To-Company Email\": \"\", \"Invoice To-Company Phone No.\": \"\", \"Invoice To-Company Address\": \" \", \"Gross Amount\": \"500.00\", \"Tax Amount\": \"60.00\", \"Discount\": \"\", \"Total Invoice Amount\": \"560.00\"}], \"Table_data_1\": [{\"S No.\": \"1\", \"Description\": \"12MM**\", \"HSN/SAC\": \"1004\", \"Quantity\": \"10\", \"Rate\": \"50.00\", \"Unit\": \"No\", \"Amount\": \"500.00\"}], \"Table_data_2\": [{\"HSN/SAC\": \"1004\", \"Value of Supply\": \"\", \"Taxable Value\": \"500.00\", \"Central Tax Amount\": \"\", \"State Tax Amount\": \"\", \"Total Tax Amount\": \"60.00\"}]}'}\n]\n\nprompt = tokenizer.apply_chat_template(message, tokenize = False, add_generation_prompt = True)\ninputs = tokenizer(prompt, return_tensors = 'pt').to('cuda')\noutputs = model.generate(**inputs, max_new_tokens = 100)\n\nresponse = tokenizer.decode(outputs[0]).split('model')[-1].strip()\nprint(response)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/inference-test-set/inference-test-set.csv')\nquestions_df = df['question'] # Assumes the file has a 'Question' column\n\ncontext = '{\"Key_value_data\": [{\"Invoice No.\": \"4545 / 2017-18\", \"Invoice Date\": \"15/09/2017\", \"Invoice From-Company Name\": \"BLUE SKY INDIA LIMITED\", \"Invoice From-Company GSTIN\": \"078DFGHJ412421SF\", \"Invoice From-Company Email\": \"test@gmail.com\", \"Invoice From-Company Phone No.\": \"+91645641236485\", \"Invoice From-Company Address\": \"Plot No. 44, Sector-20, Dwarka- 110075\", \"Invoice To-Company Name\": \"TechGuruPlus\", \"Invoice To-Company GSTIN\": \"656564566345454\", \"Invoice To-Company Email\": \"\", \"Invoice To-Company Phone No.\": \"01356656565\", \"Invoice To-Company Address\": \"C-172, Okhla Industrial Area, \\nNew Delhi-110020\", \"Gross Amount\": \"10960.00\", \"Tax Amount\": \"1952.00\", \"Discount\": \"\", \"Total Invoice Amount\": \"12932.00\"}], \"Table_data_1\": [{\"S No.\": \"45\", \"Description\": \"ITEM NAME 1\", \"HSN/SAC\": \"4556\", \"Quantity\": \"20.00\", \"Rate\": \"\", \"Unit\": \"\", \"Amount\": \"900.00\"}, {\"S No.\": \"23\", \"Description\": \"ITEM NAME 2\", \"HSN/SAC\": \"8978\", \"Quantity\": \"40.00\", \"Rate\": \"\", \"Unit\": \"\", \"Amount\": \"920.00\"}, {\"S No.\": \"56\", \"Description\": \"ITEM NAME 3\", \"HSN/SAC\": \"5645\", \"Quantity\": \"50.00\", \"Rate\": \"\", \"Unit\": \"\", \"Amount\": \"2800.00\"}, {\"S No.\": \"89\", \"Description\": \"ITEM NAME 4\", \"HSN/SAC\": \"2312\", \"Quantity\": \"60.00\", \"Rate\": \"\", \"Unit\": \"\", \"Amount\": \"5340.00\"}]}'\n\nresponses = []\n\n# Iterate over each question and generate a response\nfor question in questions_df:\n    \n    \n    # Prepare the message for the model\n    message = [\n        {\"role\": \"user\", \"content\": question},\n        {\"role\": \"system\", \"content\": context}\n    ]\n\n    # Format the prompt using the chat template\n    prompt = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n\n    # Tokenize and run the model\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(**inputs, max_new_tokens=100)\n\n    # Decode the model's output\n    response = tokenizer.decode(outputs[0]).split('model')[-1].strip()\n\n    # Append the response to the list\n    responses.append(response)\n\noutput_df = pd.DataFrame({\n    'question': questions_df,\n    'Model Response': responses\n})\n# Save the updated DataFrame to a new Excel/CSV file\noutput_df.to_excel('gemma_2_2b_it_tuned_v2_responses.xlsx', index=False)\n\nprint(\"Responses have been saved to\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}